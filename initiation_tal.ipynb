{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSH-Clermont/initiation_python/blob/main/initiation_tal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h_K8HVd_osB"
      },
      "source": [
        "-- Source : *Formation \"Initiation à l'analyse automatique de textes en SHS\" https://github.com/Consortium-ARIANE/Formation-Lyon-8-9-novembre-2023/blob/main/formation_tal_reboul/1_premier_TAL.ipynb*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuK6XXvXDzWZ"
      },
      "source": [
        "# <center>Premières expériences de Traitement Automatique de la Langue</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-JHX4YaDzWb"
      },
      "source": [
        "Vous allez maintenant apprendre à faire du traitement automatique de base. Pour ce faire, nous utiliserons **spaCy**, qui est efficace pour l'objectif de vous initier au TAL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06tuo49DzWc"
      },
      "source": [
        "La première étape c'est d'installer la bibliothèque spaCy. Pour ce faire, il faut lancer la commande `pip install spacy`. Si le module est déjà installé, le terminal vous le dira."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDMMyOfYDzWd"
      },
      "source": [
        "Il vous faut ensuite importer le module dans le carnet (lui dire où piocher ses fonctions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi9caHBADzWe"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIR4WW43DzWe"
      },
      "source": [
        "Nous allons aussi utiliser, plus tard, un module qui nous servira pour créer une représentation graphique, appelé **matplotlib**. Vous pouvez, là encore, l'importer avec `pip install matplotlib`.\n",
        "<br>Lorsque vous importez un module, vous pouvez lui donner un nom plus simple, comme ici matplotlib, qui est très souvent surnommé `plt`.\n",
        "<br>La ligne suivante configure la taille du grahique produit par défaut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHrhzeUZDzWf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = [16,9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYxJN7i3DzWg"
      },
      "source": [
        "Nous chargeons ensuite le modèle de langue que nous allons utiliser, en l'occurrence le français.\n",
        "<br>Là encore, le modèle doit être chargé par avance, en exécutant cette commande en terminal : <br><center>`python -m spacy download fr`</center>\n",
        "<br>Attention, cette commande ne marche que si `python` est par défaut la version de python 3. Si vous avez aussi python 2 sur votre ordinateur, vous devez exécuter la commande suivante : <br><center>`python3 -m spacy download fr`</center>\n",
        "<br>Ici, pas besoin, on va le faire directement dans le code.\n",
        "<br>Vous pouvez ensuite charger le modèle de langue souhaité, soit comme ça :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64X4mqwfDzWg"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download fr_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('fr_core_news_sm')"
      ],
      "metadata": {
        "id": "xutOxiWJjQRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPGcW21LDzWi"
      },
      "source": [
        "Nous chargeons ensuite un document (ici une chaîne de caractères, ou \"string\"), à analyser. Il s'agit de la préface de 1862 des <i>Misérables</i>. Le \"u\" au début hors des guillemets sert à signaler que nous voulons que la chaîne soit en unicode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQNE5FKnDzWj"
      },
      "outputs": [],
      "source": [
        "miserables=u'Tant qu’il existera, par le fait des lois et des mœurs, une damnation sociale créant artificiellement, en pleine civilisation, des enfers, et compliquant d’une fatalité humaine la destinée qui est divine ; tant que les trois problèmes du siècle, la dégradation de l’homme par le prolétariat, la déchéance de la femme par la faim, l’atrophie de l’enfant par la nuit, ne seront pas résolus ; tant que, dans de certaines régions, l’asphyxie sociale sera possible ; en d’autres termes, et à un point de vue plus étendu encore, tant qu’il y aura sur la terre ignorance et misère, des livres de la nature de celui-ci pourront ne pas être inutiles.'\n",
        "\n",
        "doc = nlp(miserables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCydQeFNDzWk"
      },
      "source": [
        "Je veux par exemple écrire tout le texte. SpaCy va stocker l'ensemble des information d'un token dans la variable \"token\", qui comporte différentes caractéristiques (text, lemma_, pos_, etc.). Nous allons utiliser une boucle pour parcourir l'ensemble des données stockées par spaCy dans la variable `doc`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reLakK2eDzWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60b18dd-61af-42ef-bd19-ae0aed232486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tant\n",
            "qu’\n",
            "il\n",
            "existera\n",
            ",\n",
            "par\n",
            "le\n",
            "fait\n",
            "des\n",
            "lois\n",
            "et\n",
            "des\n",
            "mœurs\n",
            ",\n",
            "une\n",
            "damnation\n",
            "sociale\n",
            "créant\n",
            "artificiellement\n",
            ",\n",
            "en\n",
            "pleine\n",
            "civilisation\n",
            ",\n",
            "des\n",
            "enfers\n",
            ",\n",
            "et\n",
            "compliquant\n",
            "d’\n",
            "une\n",
            "fatalité\n",
            "humaine\n",
            "la\n",
            "destinée\n",
            "qui\n",
            "est\n",
            "divine\n",
            ";\n",
            "tant\n",
            "que\n",
            "les\n",
            "trois\n",
            "problèmes\n",
            "du\n",
            "siècle\n",
            ",\n",
            "la\n",
            "dégradation\n",
            "de\n",
            "l’\n",
            "homme\n",
            "par\n",
            "le\n",
            "prolétariat\n",
            ",\n",
            "la\n",
            "déchéance\n",
            "de\n",
            "la\n",
            "femme\n",
            "par\n",
            "la\n",
            "faim\n",
            ",\n",
            "l’\n",
            "atrophie\n",
            "de\n",
            "l’\n",
            "enfant\n",
            "par\n",
            "la\n",
            "nuit\n",
            ",\n",
            "ne\n",
            "seront\n",
            "pas\n",
            "résolus\n",
            ";\n",
            "tant\n",
            "que\n",
            ",\n",
            "dans\n",
            "de\n",
            "certaines\n",
            "régions\n",
            ",\n",
            "l’\n",
            "asphyxie\n",
            "sociale\n",
            "sera\n",
            "possible\n",
            ";\n",
            "en\n",
            "d’\n",
            "autres\n",
            "termes\n",
            ",\n",
            "et\n",
            "à\n",
            "un\n",
            "point\n",
            "de\n",
            "vue\n",
            "plus\n",
            "étendu\n",
            "encore\n",
            ",\n",
            "tant\n",
            "qu’\n",
            "il\n",
            "y\n",
            "aura\n",
            "sur\n",
            "la\n",
            "terre\n",
            "ignorance\n",
            "et\n",
            "misère\n",
            ",\n",
            "des\n",
            "livres\n",
            "de\n",
            "la\n",
            "nature\n",
            "de\n",
            "celui-ci\n",
            "pourront\n",
            "ne\n",
            "pas\n",
            "être\n",
            "inutiles\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXknQ8iBDzWl"
      },
      "source": [
        "Je peux faire la même chose avec les lemmes,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9wrzs-PDzWl"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token.lemma_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVzHMxNDzWm"
      },
      "source": [
        "ou avec les étiquettes de nature :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj5zVCsCDzWm"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_0VKFDgDzWm"
      },
      "source": [
        "ou les trois :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4FiSgYJDzWm"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token.text+\" \"+token.lemma_+\" \"+token.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G42X0J_VDzWn"
      },
      "source": [
        "Mettons maintenant que je veuille savoir quelle est la proportion des noms, verbes, adjectifs, etc. dans un texte. Et que je veuille le représenter graphiquement.\n",
        "<br>Je vais d'abord compter le nombre d'éléments dans chaque catégorie, comme ça :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mRh-8_BDzWn"
      },
      "outputs": [],
      "source": [
        "advs=0\n",
        "nouns=0\n",
        "vbs=0\n",
        "adjs=0\n",
        "conjs=0\n",
        "for token in doc:\n",
        "    if token.pos_ == \"ADV\":\n",
        "        advs+=1\n",
        "    elif token.pos_ == \"NOUN\":\n",
        "        nouns+=1\n",
        "    elif token.pos_ == \"VERB\":\n",
        "        vbs+=1\n",
        "    elif token.pos_ == \"ADJ\":\n",
        "        adjs+=1\n",
        "    elif token.pos_ == \"SCONJ\":\n",
        "        conjs+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3m2px0NDzWn"
      },
      "source": [
        "Maintenant, les variables `advs`, `nouns`, `vbs` etc. comportent toutes le nombre absolu d'éléments présents dans le texte.\n",
        "<br>Mais je veux obtenir une proportion, donc je vais faire un simple produit en croix, pour obtenir le pourcentage de chaque élément.\n",
        "<br>Je vais stocker le pourcentage de chaque élément dans une liste, appelée `parts`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmqZQj2SDzWo"
      },
      "outputs": [],
      "source": [
        "total_len=nouns+vbs+adjs+conjs+advs\n",
        "nNames=(nouns*100)/total_len\n",
        "nVerbs=(vbs*100)/total_len\n",
        "nAdjectives=(adjs*100)/total_len\n",
        "nConj=(conjs*100)/total_len\n",
        "nAdverbs=(advs*100)/total_len\n",
        "parts=[nNames,nVerbs,nConj,nAdjectives,nAdverbs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCaAmKOcDzWo"
      },
      "source": [
        "Enfin je vais créer le graphique en camembert, avec la librairie matplotlib renommée `plt`. Je vais pour cela donner des noms à mes éléments (les légender), et leur attribuer une couleur.\n",
        "<br>Je peux aussi, avec la valeur de `explode`, une liste qui comporte pour chaque élément soit 1 soit 0, demander à ce qu'une partie du camembert soit détachée du reste. Je peux aussi déterminer l'angle de démarrage du camembert (`startangle`), ou dire si je veux du relief (`shadow`, paramètre qui est soit `True` soit `False`).\n",
        "<br>Enfin, je demande à matplotlib de me montrer le résultat avec `show()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5xfk-n3DzWo"
      },
      "outputs": [],
      "source": [
        "labels = 'Nouns','Verbs','Conjs','Adjectives','Advbs'\n",
        "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue','orange']\n",
        "explode = (0.1, 0, 0,0,0 )\n",
        "plt.pie(parts, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
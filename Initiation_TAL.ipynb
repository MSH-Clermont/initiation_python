{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSH-Clermont/initiation_python/blob/main/Initiation_TAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h_K8HVd_osB"
      },
      "source": [
        "-- Source : *Formation \"Initiation à l'analyse automatique de textes en SHS\" Le cours de Marianne Reboul https://github.com/Consortium-ARIANE/Formation-Lyon-8-9-novembre-2023/blob/main/formation_tal_reboul/1_premier_TAL.ipynb*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuK6XXvXDzWZ"
      },
      "source": [
        "# <center>Premières expériences de Traitement Automatique de la Langue</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-JHX4YaDzWb"
      },
      "source": [
        "Vous allez maintenant apprendre à faire du traitement automatique de base. Pour ce faire, nous utiliserons **spaCy**, qui est efficace pour l'objectif de vous initier au TAL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06tuo49DzWc"
      },
      "source": [
        "La première étape c'est d'installer la bibliothèque spaCy. Pour ce faire, il faut lancer la commande `pip install spacy`. Si le module est déjà installé, le terminal vous le dira."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "AIIf02Xd883b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDMMyOfYDzWd"
      },
      "source": [
        "Il vous faut ensuite importer le module dans le carnet (lui dire où piocher ses fonctions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Oi9caHBADzWe"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64X4mqwfDzWg"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download fr_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('fr_core_news_sm')"
      ],
      "metadata": {
        "id": "xutOxiWJjQRR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger les stopwords de SpaCy\n",
        "more_stopwords = set(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "id": "ZR8R3ESQWCi9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPGcW21LDzWi"
      },
      "source": [
        "Nous chargeons ensuite un texte (ici une chaîne de caractères, ou \"string\"), à analyser. Il s'agit de la préface de 1862 des <i>Misérables</i>. Le \"u\" au début hors des guillemets sert à signaler que nous voulons que la chaîne soit en unicode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mQNE5FKnDzWj"
      },
      "outputs": [],
      "source": [
        "miserables=u'Tant qu’il existera, par le fait des lois et des mœurs, une damnation sociale créant artificiellement, en pleine civilisation, des enfers, et compliquant d’une fatalité humaine la destinée qui est divine ; tant que les trois problèmes du siècle, la dégradation de l’homme par le prolétariat, la déchéance de la femme par la faim, l’atrophie de l’enfant par la nuit, ne seront pas résolus ; tant que, dans de certaines régions, l’asphyxie sociale sera possible ; en d’autres termes, et à un point de vue plus étendu encore, tant qu’il y aura sur la terre ignorance et misère, des livres de la nature de celui-ci pourront ne pas être inutiles.'\n",
        "\n",
        "doc = nlp(miserables)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCydQeFNDzWk"
      },
      "source": [
        "Je veux par exemple écrire tout le texte. SpaCy va stocker l'ensemble des information d'un token dans la variable \"token\", qui comporte différentes caractéristiques (text, lemma_, pos_, etc.). Nous allons utiliser une boucle pour parcourir l'ensemble des données stockées par spaCy dans la variable `doc`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reLakK2eDzWk"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXknQ8iBDzWl"
      },
      "source": [
        "Je peux faire la même chose avec les lemmes,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9wrzs-PDzWl"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token.lemma_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVzHMxNDzWm"
      },
      "source": [
        "ou avec les étiquettes de nature :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj5zVCsCDzWm"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_0VKFDgDzWm"
      },
      "source": [
        "ou les trois :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4FiSgYJDzWm"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token.text+\" \"+token.lemma_+\" \"+token.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G42X0J_VDzWn"
      },
      "source": [
        "Mettons maintenant que je veuille savoir quelle est la proportion des noms, verbes, adjectifs, etc. dans un texte. Et que je veuille le représenter graphiquement.\n",
        "<br>Je vais d'abord compter le nombre d'éléments dans chaque catégorie, comme ça :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mRh-8_BDzWn"
      },
      "outputs": [],
      "source": [
        "advs=0\n",
        "nouns=0\n",
        "vbs=0\n",
        "adjs=0\n",
        "conjs=0\n",
        "for token in doc:\n",
        "    if token.pos_ == \"ADV\":\n",
        "        advs+=1\n",
        "    elif token.pos_ == \"NOUN\":\n",
        "        nouns+=1\n",
        "    elif token.pos_ == \"VERB\":\n",
        "        vbs+=1\n",
        "    elif token.pos_ == \"ADJ\":\n",
        "        adjs+=1\n",
        "    elif token.pos_ == \"SCONJ\":\n",
        "        conjs+=1\n",
        "print(advs,nouns,vbs,adjs,conjs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3m2px0NDzWn"
      },
      "source": [
        "Maintenant, les variables `advs`, `nouns`, `vbs` etc. comportent toutes le nombre absolu d'éléments présents dans le texte.\n",
        "<br>Mais je veux obtenir une proportion, donc je vais faire un simple produit en croix, pour obtenir le pourcentage de chaque élément.\n",
        "<br>Je vais stocker le pourcentage de chaque élément dans une liste, appelée `parts`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wmqZQj2SDzWo"
      },
      "outputs": [],
      "source": [
        "total_len=nouns+vbs+adjs+conjs+advs\n",
        "\n",
        "nNames=(nouns*100)/total_len\n",
        "\n",
        "nVerbs=(vbs*100)/total_len\n",
        "\n",
        "nAdjectives=(adjs*100)/total_len\n",
        "\n",
        "nConj=(conjs*100)/total_len\n",
        "\n",
        "nAdverbs=(advs*100)/total_len\n",
        "\n",
        "parts=[nNames,nVerbs,nConj,nAdjectives,nAdverbs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIR4WW43DzWe"
      },
      "source": [
        "Nous allons aussi utiliser un module qui nous servira pour créer une représentation graphique, appelé **matplotlib**. Vous pouvez, là encore, l'importer avec `pip install matplotlib`.\n",
        "<br>Lorsque vous importez un module, vous pouvez lui donner un nom plus simple, comme ici matplotlib, qui est très souvent surnommé `plt`.\n",
        "<br>La ligne suivante configure la taille du grahique produit par défaut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCaAmKOcDzWo"
      },
      "source": [
        "Enfin je vais créer le graphique en camembert, avec la librairie matplotlib renommée `plt`. Je vais pour cela donner des noms à mes éléments (les légender), et leur attribuer une couleur.\n",
        "<br>Je peux aussi, avec la valeur de `explode`, une liste qui comporte pour chaque élément soit 1 soit 0, demander à ce qu'une partie du camembert soit détachée du reste. Je peux aussi déterminer l'angle de démarrage du camembert (`startangle`), ou dire si je veux du relief (`shadow`, paramètre qui est soit `True` soit `False`).\n",
        "<br>Enfin, je demande à matplotlib de me montrer le résultat avec `show()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GHrhzeUZDzWf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = [16,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5xfk-n3DzWo"
      },
      "outputs": [],
      "source": [
        "legende = ('Nouns','Verbs','Conjs','Adjectives','Advbs')\n",
        "colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue','orange']\n",
        "explode = (0.1, 0,0,0,0 )\n",
        "plt.pie(parts, explode=explode, labels=legende, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utiliser des commandes linux pour se déplacer dans les dossiers"
      ],
      "metadata": {
        "id": "3-XHtKA-rBWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autorisez Colab à accéder au Drive (accordez toutes les autorisation demandées)"
      ],
      "metadata": {
        "id": "n96A6NNIrayh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B449XD08ug_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creez un dossier appellé `data` dans MyDrive et ajoutez y le fichier `BUCA_Bastaire_Roman_Aventures_C95403`"
      ],
      "metadata": {
        "id": "71gshiuxJV-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "commande linux pour connaître le dossier dans lequels on se trouve"
      ],
      "metadata": {
        "id": "kj2fu3l3z82_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "wFaaBYpWzJvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "commande linux pour connaître le contenu du dossier dans lequels on se trouve"
      ],
      "metadata": {
        "id": "0_nypJB8zrER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "v6ghYcpSy3ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "commande linux pour se déplacer dans les dossiers"
      ],
      "metadata": {
        "id": "Um-FCcfp0IGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/data"
      ],
      "metadata": {
        "id": "8liQTcO_2U0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Charger un fichier depuis Drive et lecture du fichier par Python"
      ],
      "metadata": {
        "id": "tLAVfq-nLjU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fichier = \"BUCA_Bastaire_Roman_Aventures_C95403.txt\"\n",
        "\n",
        "romanOuvert = open (fichier, \"r\", encoding=\"utf-8\") # ouverture du fichier\n",
        "policier = romanOuvert.read() # lecture du fichier\n",
        "\n",
        "print(policier)"
      ],
      "metadata": {
        "id": "F6aj8gbeJ0VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###QUIZ : Affichier seulement les 100 premiers mots du texte"
      ],
      "metadata": {
        "id": "g7tkDz0nL9nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# première solution\n",
        "nouveauxDoc = nlp(policier) #crée un objet document qui est itérable\n",
        "for token in nouveauxDoc[:100]:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "id": "Wk7slcwrLgwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# votre code ici pour appliquer une autre méthode\n"
      ],
      "metadata": {
        "id": "nSozB5kcPBl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prétraitement pour normaliser, corriger et uniformiser le texte"
      ],
      "metadata": {
        "id": "N07H9b2JabdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lit le contenu du fichier et le convertit en minuscules\n",
        "minuscules = policier.lower()\n",
        "print(minuscules)"
      ],
      "metadata": {
        "id": "xnhjpmXYanBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# suprrime les espaces vides\n",
        "sansEspace = \" \".join (minuscules.split())\n",
        "print(sansEspace)"
      ],
      "metadata": {
        "id": "V5LlYXSffYm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajout des ponctuations spécifiques\n",
        "#from string import punctuation\n",
        "punctuation = \"&↩•—.,!...?:;\""
      ],
      "metadata": {
        "id": "f6c2BpYGa59N"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer une liste pour stocker les caractères filtrés\n",
        "filtered_chars = []\n",
        "# Parcourir chaque caractère dans le texte\n",
        "for c in sansEspace:\n",
        "    # Vérifier si le caractère n'est pas dans la liste de ponctuation\n",
        "    if c not in punctuation:\n",
        "        # Si le caractère n'est pas une ponctuation, l'ajouter à la liste\n",
        "        filtered_chars.append(c)\n",
        "\n",
        "# Joindre les caractères filtrés en une seule chaîne\n",
        "textSansPonctuation = ''.join(filtered_chars)\n",
        "print(textSansPonctuation)"
      ],
      "metadata": {
        "id": "Dx_4NDA-bE6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(textSansPonctuation)\n",
        "\n",
        "for token in doc[:100]:\n",
        "    print(token.text, token.lemma_, token.pos_)"
      ],
      "metadata": {
        "id": "2YNt67r2d7oZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}